{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# American Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data config\n",
    "path_to_csv = \"adult.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  education-num  hours-per-week     workclass      education  \\\n",
      "0   30            9.0              40       Private        HS-grad   \n",
      "1   77           10.0               6           NaN   Some-college   \n",
      "2   44           12.0              50       Private     Assoc-acdm   \n",
      "3   53           10.0              50       Private   Some-college   \n",
      "4   41           10.0              40   Federal-gov   Some-college   \n",
      "\n",
      "        marital-status         occupation    relationship  \\\n",
      "0   Married-civ-spouse              Sales       Own-child   \n",
      "1   Married-civ-spouse                NaN         Husband   \n",
      "2        Never-married     Prof-specialty       Unmarried   \n",
      "3        Never-married       Adm-clerical   Not-in-family   \n",
      "4   Married-civ-spouse   Transport-moving            Wife   \n",
      "\n",
      "                  race      sex  native-country  \n",
      "0   Asian-Pac-Islander   Female   United-States  \n",
      "1                White     Male   United-States  \n",
      "2                Black   Female   United-States  \n",
      "3                White   Female   United-States  \n",
      "4                White   Female   United-States  \n",
      "<bound method NDFrame.describe of        age  education-num  hours-per-week     workclass      education  \\\n",
      "0       30            9.0              40       Private        HS-grad   \n",
      "1       77           10.0               6           NaN   Some-college   \n",
      "2       44           12.0              50       Private     Assoc-acdm   \n",
      "3       53           10.0              50       Private   Some-college   \n",
      "4       41           10.0              40   Federal-gov   Some-college   \n",
      "...    ...            ...             ...           ...            ...   \n",
      "16275   31           11.0              30       Private      Assoc-voc   \n",
      "16276   37           13.0              40     State-gov      Bachelors   \n",
      "16277   45           14.0              40     State-gov        Masters   \n",
      "16278   32            9.0              40       Private        HS-grad   \n",
      "16279   58            7.0              50       Private           11th   \n",
      "\n",
      "            marital-status          occupation    relationship  \\\n",
      "0       Married-civ-spouse               Sales       Own-child   \n",
      "1       Married-civ-spouse                 NaN         Husband   \n",
      "2            Never-married      Prof-specialty       Unmarried   \n",
      "3            Never-married        Adm-clerical   Not-in-family   \n",
      "4       Married-civ-spouse    Transport-moving            Wife   \n",
      "...                    ...                 ...             ...   \n",
      "16275   Married-civ-spouse    Transport-moving         Husband   \n",
      "16276        Never-married      Prof-specialty   Not-in-family   \n",
      "16277             Divorced     Exec-managerial       Unmarried   \n",
      "16278        Never-married   Machine-op-inspct   Not-in-family   \n",
      "16279   Married-civ-spouse    Transport-moving         Husband   \n",
      "\n",
      "                      race      sex  native-country  \n",
      "0       Asian-Pac-Islander   Female   United-States  \n",
      "1                    White     Male   United-States  \n",
      "2                    Black   Female   United-States  \n",
      "3                    White   Female   United-States  \n",
      "4                    White   Female   United-States  \n",
      "...                    ...      ...             ...  \n",
      "16275                White     Male   United-States  \n",
      "16276                White   Female   United-States  \n",
      "16277                White   Female   United-States  \n",
      "16278                White     Male   United-States  \n",
      "16279                White     Male   United-States  \n",
      "\n",
      "[16280 rows x 11 columns]>\n",
      "[    1    26    35 ... 16253 16256 16267]\n",
      "[    1    26    35    37    47    90   128   137   227   249   253   258\n",
      "   295   297   310   311   316   341   436   466   479   497   503   507\n",
      "   520   522   534   542   550   574   578   580   581   593   610   614\n",
      "   635   650   658   706   757   772   787   797   802   805   863   881\n",
      "   885   909   917   926   929   942   963   985   991  1026  1030  1031\n",
      "  1036  1054  1074  1087  1129  1138  1150  1196  1251  1261  1266  1282\n",
      "  1288  1307  1387  1391  1400  1403  1419  1446  1449  1482  1543  1563\n",
      "  1570  1583  1604  1605  1619  1642  1650  1657  1702  1704  1736  1752\n",
      "  1767  1772  1774  1796  1808  1824  1835  1886  1902  1909  1920  1947\n",
      "  1954  2015  2023  2033  2037  2042  2044  2046  2137  2148  2163  2193\n",
      "  2216  2223  2238  2247  2280  2291  2302  2308  2404  2419  2426  2438\n",
      "  2463  2492  2543  2545  2548  2554  2580  2587  2599  2606  2638  2639\n",
      "  2648  2683  2690  2693  2701  2724  2737  2786  2795  2809  2821  2835\n",
      "  2858  2864  2867  2884  2889  2891  2917  2945  2948  2979  2988  3007\n",
      "  3013  3017  3033  3034  3041  3044  3063  3104  3140  3143  3146  3150\n",
      "  3159  3165  3180  3185  3186  3211  3222  3229  3246  3251  3283  3325\n",
      "  3336  3341  3354  3385  3391  3395  3423  3448  3480  3492  3493  3541\n",
      "  3590  3596  3597  3609  3611  3632  3650  3662  3692  3707  3757  3763\n",
      "  3769  3793  3824  3861  3881  3898  3922  3933  3951  3969  3972  3986\n",
      "  4006  4013  4043  4057  4076  4086  4090  4097  4107  4114  4188  4209\n",
      "  4248  4274  4295  4304  4316  4330  4352  4375  4472  4490  4504  4505\n",
      "  4511  4520  4527  4538  4550  4555  4565  4578  4601  4628  4644  4650\n",
      "  4652  4685  4753  4774  4793  4816  4832  4839  4863  4887  4927  4928\n",
      "  4945  4953  4954  4961  5062  5124  5128  5132  5157  5191  5201  5216\n",
      "  5230  5257  5260  5291  5292  5293  5295  5296  5312  5319  5323  5333\n",
      "  5346  5347  5350  5353  5402  5436  5456  5474  5484  5489  5548  5553\n",
      "  5589  5595  5601  5605  5614  5616  5632  5634  5644  5661  5667  5688\n",
      "  5721  5727  5769  5785  5812  5816  5821  5822  5865  5869  5880  5904\n",
      "  5906  5931  5933  5951  5953  5958  5961  5972  5986  6006  6012  6059\n",
      "  6078  6085  6092  6118  6121  6127  6140  6154  6155  6158  6192  6214\n",
      "  6234  6242  6243  6275  6288  6311  6325  6338  6360  6380  6390  6416\n",
      "  6421  6462  6524  6532  6595  6613  6634  6639  6653  6656  6663  6702\n",
      "  6730  6734  6736  6767  6782  6794  6811  6815  6821  6840  6865  6868\n",
      "  6888  6978  6980  6983  6988  7094  7097  7128  7138  7140  7150  7183\n",
      "  7226  7233  7239  7242  7251  7271  7274  7283  7285  7340  7378  7384\n",
      "  7393  7409  7434  7454  7467  7479  7498  7510  7517  7541  7578  7626\n",
      "  7661  7665  7666  7683  7717  7750  7771  7789  7795  7835  7841  7875\n",
      "  7889  7942  7946  7971  7975  8027  8062  8133  8145  8160  8170  8172\n",
      "  8229  8253  8266  8278  8291  8334  8352  8357  8367  8387  8400  8404\n",
      "  8406  8430  8467  8474  8480  8482  8485  8487  8488  8504  8510  8513\n",
      "  8524  8559  8562  8581  8582  8620  8632  8639  8640  8650  8666  8669\n",
      "  8738  8746  8750  8753  8765  8787  8839  8842  8873  8882  8888  8897\n",
      "  8900  8901  8970  8988  9017  9049  9052  9058  9110  9140  9143  9149\n",
      "  9151  9177  9178  9186  9189  9220  9251  9297  9336  9339  9371  9391\n",
      "  9400  9427  9447  9450  9464  9471  9495  9530  9534  9549  9555  9565\n",
      "  9573  9584  9646  9674  9684  9744  9759  9774  9777  9778  9784  9785\n",
      "  9792  9800  9820  9826  9833  9855  9857  9876  9888  9896  9912  9942\n",
      "  9943  9945  9969  9980 10024 10038 10094 10115 10142 10153 10173 10190\n",
      " 10202 10209 10230 10261 10282 10312 10318 10330 10350 10361 10364 10396\n",
      " 10402 10414 10416 10461 10471 10506 10527 10540 10604 10613 10640 10658\n",
      " 10660 10688 10741 10754 10766 10783 10799 10810 10873 10949 10962 10970\n",
      " 10976 10982 10994 10997 11038 11043 11047 11060 11075 11081 11085 11097\n",
      " 11159 11163 11176 11179 11227 11230 11255 11267 11309 11319 11325 11367\n",
      " 11375 11377 11423 11435 11447 11495 11512 11517 11521 11531 11555 11565\n",
      " 11618 11642 11673 11682 11695 11745 11758 11793 11796 11803 11812 11842\n",
      " 11853 11854 11887 11903 11929 11934 11940 11981 12006 12038 12039 12068\n",
      " 12071 12096 12100 12107 12124 12142 12154 12172 12203 12221 12234 12271\n",
      " 12278 12290 12291 12333 12335 12344 12379 12390 12410 12442 12444 12451\n",
      " 12499 12505 12509 12524 12536 12542 12545 12556 12560 12568 12583 12586\n",
      " 12592 12612 12624 12648 12684 12685 12694 12726 12736 12751 12760 12761\n",
      " 12768 12779 12780 12813 12836 12866 12867 12870 12873 12878 12883 12890\n",
      " 12892 12903 12905 12933 12939 12941 12968 12993 12996 13040 13059 13062\n",
      " 13063 13077 13086 13096 13116 13147 13155 13157 13164 13167 13252 13302\n",
      " 13316 13336 13372 13387 13392 13398 13406 13424 13440 13489 13512 13515\n",
      " 13524 13535 13574 13586 13612 13623 13663 13666 13667 13697 13707 13717\n",
      " 13736 13737 13773 13777 13782 13786 13823 13827 13855 13859 13864 13918\n",
      " 13927 13936 13938 13948 13954 13963 13973 13983 13987 13993 13996 14064\n",
      " 14093 14120 14123 14137 14228 14230 14233 14282 14284 14286 14303 14327\n",
      " 14379 14385 14387 14419 14430 14433 14434 14451 14470 14487 14494 14495\n",
      " 14496 14515 14529 14537 14559 14564 14569 14595 14601 14612 14625 14627\n",
      " 14634 14663 14681 14699 14709 14730 14766 14777 14789 14805 14812 14846\n",
      " 14961 14982 14997 15003 15004 15011 15021 15038 15099 15101 15116 15117\n",
      " 15121 15125 15128 15143 15194 15218 15219 15220 15275 15285 15290 15328\n",
      " 15332 15335 15351 15369 15409 15441 15476 15488 15523 15526 15536 15545\n",
      " 15570 15575 15579 15592 15643 15673 15683 15707 15736 15755 15784 15785\n",
      " 15801 15830 15835 15856 15865 15875 15876 15878 15891 15926 15930 15964\n",
      " 15982 15997 16004 16009 16045 16058 16063 16071 16072 16090 16091 16093\n",
      " 16101 16115 16129 16133 16163 16195 16209 16217 16234 16251 16253 16256]\n",
      "28    452\n",
      "31    448\n",
      "35    437\n",
      "36    436\n",
      "33    436\n",
      "     ... \n",
      "82      7\n",
      "83      4\n",
      "85      2\n",
      "88      1\n",
      "87      1\n",
      "Name: age, Length: 72, dtype: int64\n",
      "9.0     5132\n",
      "10.0    3607\n",
      "13.0    2683\n",
      "14.0     833\n",
      "11.0     712\n",
      "7.0      594\n",
      "12.0     524\n",
      "6.0      463\n",
      "4.0      300\n",
      "15.0     270\n",
      "5.0      247\n",
      "8.0      205\n",
      "16.0     204\n",
      "3.0      160\n",
      "2.0       80\n",
      "1.0       26\n",
      "Name: education-num, dtype: int64\n",
      "40    7575\n",
      "50    1407\n",
      "45     922\n",
      "60     732\n",
      "35     655\n",
      "      ... \n",
      "94       1\n",
      "61       1\n",
      "98       1\n",
      "82       1\n",
      "95       1\n",
      "Name: hours-per-week, Length: 89, dtype: int64\n",
      " Private             11352\n",
      " Self-emp-not-inc     1263\n",
      " Local-gov            1063\n",
      " State-gov             628\n",
      " Self-emp-inc          574\n",
      " Federal-gov           453\n",
      " Without-pay             8\n",
      " Never-worked            3\n",
      "Name: workclass, dtype: int64\n",
      " HS-grad         5210\n",
      " Some-college    3662\n",
      " Bachelors       2720\n",
      " Masters          847\n",
      " Assoc-voc        722\n",
      " 11th             607\n",
      " Assoc-acdm       531\n",
      " 10th             470\n",
      " 7th-8th          302\n",
      " Prof-school      274\n",
      " 9th              251\n",
      " Doctorate        209\n",
      " 12th             207\n",
      " 5th-6th          162\n",
      " 1st-4th           80\n",
      " Preschool         26\n",
      "Name: education, dtype: int64\n",
      " Married-civ-spouse       7464\n",
      " Never-married            5349\n",
      " Divorced                 2208\n",
      " Separated                 510\n",
      " Widowed                   500\n",
      " Married-spouse-absent     233\n",
      " Married-AF-spouse          16\n",
      "Name: marital-status, dtype: int64\n",
      " Prof-specialty       2083\n",
      " Exec-managerial      1976\n",
      " Craft-repair         1969\n",
      " Adm-clerical         1886\n",
      " Sales                1824\n",
      " Other-service        1618\n",
      " Machine-op-inspct     992\n",
      " Transport-moving      771\n",
      " Handlers-cleaners     649\n",
      " Farming-fishing       496\n",
      " Tech-support          440\n",
      " Protective-serv       323\n",
      " Priv-house-serv        68\n",
      " Armed-Forces            4\n",
      "Name: occupation, dtype: int64\n",
      " Husband           6545\n",
      " Not-in-family     4192\n",
      " Own-child         2538\n",
      " Unmarried         1708\n",
      " Wife               806\n",
      " Other-relative     491\n",
      "Name: relationship, dtype: int64\n",
      " White                 13953\n",
      " Black                  1537\n",
      " Asian-Pac-Islander      506\n",
      " Amer-Indian-Eskimo      146\n",
      " Other                   138\n",
      "Name: race, dtype: int64\n",
      " Male      10883\n",
      " Female     5397\n",
      "Name: sex, dtype: int64\n",
      " United-States                 14598\n",
      " Mexico                          311\n",
      " Philippines                      85\n",
      " Canada                           67\n",
      " Germany                          66\n",
      " Puerto-Rico                      63\n",
      " El-Salvador                      58\n",
      " India                            57\n",
      " Cuba                             44\n",
      " Jamaica                          43\n",
      " England                          43\n",
      " South                            41\n",
      " China                            38\n",
      " Poland                           35\n",
      " Japan                            32\n",
      " Vietnam                          31\n",
      " Italy                            30\n",
      " Columbia                         29\n",
      " Guatemala                        28\n",
      " Iran                             27\n",
      " Dominican-Republic               26\n",
      " Nicaragua                        21\n",
      " Taiwan                           21\n",
      " Portugal                         21\n",
      " Haiti                            16\n",
      " Ecuador                          15\n",
      " Greece                           15\n",
      " Peru                             15\n",
      " Laos                             13\n",
      " France                           12\n",
      " Trinadad&Tobago                  11\n",
      " Hungary                          11\n",
      " Cambodia                         11\n",
      " Ireland                          10\n",
      " Yugoslavia                        9\n",
      " Hong                              9\n",
      " Thailand                          7\n",
      " Honduras                          5\n",
      " Outlying-US(Guam-USVI-etc)        3\n",
      " Scotland                          3\n",
      "Name: native-country, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.head())\n",
    "\n",
    "print(X_train.describe)\n",
    "\n",
    "X_train.isnull().sum()\n",
    "\n",
    "print(np.where(X_train['occupation'].isnull())[0])\n",
    "print(np.where(X_train['workclass'].isna())[0])\n",
    "\n",
    "for i in range(len(X_train.columns)):\n",
    "    print(X_train[X_train.columns[i]].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This question is answered in the report.\n"
     ]
    }
   ],
   "source": [
    "print(\"This question is answered in the report.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16280\n",
      "16280\n",
      "14707\n",
      "14707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "education-num     0\n",
       "hours-per-week    0\n",
       "workclass         0\n",
       "education         0\n",
       "marital-status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "native-country    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()\n",
    "print(len(X_train))\n",
    "\n",
    "indices_of_nan = np.array(np.where(X_train.isna())[0])\n",
    "\n",
    "indices_of_nan = np.unique(indices_of_nan, axis=0)\n",
    "\n",
    "print(len(y_train))\n",
    "y_train = y_train.drop(index=indices_of_nan)\n",
    "print(len(y_train))\n",
    "X_train = X_train.dropna()\n",
    "\n",
    "X_train.isnull().sum()\n",
    "print(len(X_train))\n",
    "\n",
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  education-num  hours-per-week\n",
      "0       30            9.0              40\n",
      "2       44           12.0              50\n",
      "3       53           10.0              50\n",
      "4       41           10.0              40\n",
      "5       50           14.0              50\n",
      "...    ...            ...             ...\n",
      "16275   31           11.0              30\n",
      "16276   37           13.0              40\n",
      "16277   45           14.0              40\n",
      "16278   32            9.0              40\n",
      "16279   58            7.0              50\n",
      "\n",
      "[14707 rows x 3 columns]\n",
      "       age  education-num  hours-per-week\n",
      "0       30            9.0              40\n",
      "2       44           12.0              50\n",
      "3       53           10.0              50\n",
      "4       41           10.0              40\n",
      "5       50           14.0              50\n",
      "...    ...            ...             ...\n",
      "16275   31           11.0              30\n",
      "16276   37           13.0              40\n",
      "16277   45           14.0              40\n",
      "16278   32            9.0              40\n",
      "16279   58            7.0              50\n",
      "\n",
      "[14707 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "\n",
    "# select columns with numerical data types\n",
    "num_columns_train = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "# select a subset of the dataframe with the numerical columns\n",
    "num_subset_train = X_train[num_columns_train]\n",
    "print(num_subset_train)\n",
    "\n",
    "# select columns with numerical data types\n",
    "num_columns_test = X_test.select_dtypes(include=['int64', 'float64']).columns\n",
    "# select a subset of the dataframe with the numerical columns\n",
    "num_subset_test = X_test[num_columns_test]\n",
    "print(num_subset_train)\n",
    "\n",
    "cat_columns_train = X_train.select_dtypes(include=['object']).columns\n",
    "cat_subset_train = X_train[cat_columns_train]\n",
    "\n",
    "cat_columns_test = X_test.select_dtypes(include=['object']).columns\n",
    "cat_subset_test = X_test[cat_columns_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "steps = list()\n",
    "steps.append(('c', OneHotEncoder(handle_unknown='ignore'), cat_columns_train))\n",
    "steps.append(('n', MinMaxScaler(), num_columns_train))\n",
    "\n",
    "# define steps\n",
    "steps = [('c', OneHotEncoder(handle_unknown='ignore'), cat_columns_train), ('n', MinMaxScaler(), num_columns_train)]\n",
    "# one hot encode categorical, normalize numerical\n",
    "ct = ColumnTransformer(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# split data\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_train, y_train, test_size=0.2,\n",
    "                                                                random_state=42, shuffle=True, stratify=y_train)\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "models = {\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"DummyClassifier\": DummyClassifier(strategy=\"most_frequent\"),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(max_depth=None, min_samples_leaf=2, random_state=random_state),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(n_neighbors=3, weights=\"distance\"),\n",
    "    # START ANSWER\n",
    "    # 𝐄𝐱𝐞𝐫𝐜𝐢𝐬𝐞 1  Extent the list of models with theSVC and LogisticRegression algorithms.\n",
    "    # Give the SVM a poly kernel. Also, give both algorithms a regularization constant C=0.5 and random_state=42.\n",
    "    \"SVM\": SVC(kernel='poly', C=10, random_state=42),\n",
    "    \"LogisticRegression\": LogisticRegression(C=10, random_state=42, penalty='none')\n",
    "    # END ANSWER\n",
    "}\n",
    "\n",
    "assert \"GaussianNB\" in models and isinstance(models[\"GaussianNB\"], GaussianNB), \"There is no GaussianNB in models\"\n",
    "assert \"DecisionTreeClassifier\" in models and isinstance(models[\"DecisionTreeClassifier\"],\n",
    "                                                         DecisionTreeClassifier), \"There is no DecisionTreeClassifier in models\"\n",
    "assert \"KNeighborsClassifier\" in models and isinstance(models[\"KNeighborsClassifier\"],\n",
    "                                                       KNeighborsClassifier), \"There is no KNeighborsClassifier in models\"\n",
    "assert \"SVM\" in models and isinstance(models[\"SVM\"], SVC), \"There is no SVC in models\"\n",
    "assert \"LogisticRegression\" in models and isinstance(models[\"LogisticRegression\"],\n",
    "                                                     LogisticRegression), \"There is no LogisticRegression in models\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc score\n",
      ">GaussianNB 0.407 (0.013)\n",
      "f1 score\n",
      ">GaussianNB 0.382 (0.019)\n",
      "auc-roc score\n",
      ">GaussianNB 0.593 (0.006)\n",
      "acc score\n",
      ">DummyClassifier 0.750 (0.000)\n",
      "f1 score\n",
      ">DummyClassifier 0.643 (0.000)\n",
      "auc-roc score\n",
      ">DummyClassifier 0.500 (0.000)\n",
      "acc score\n",
      ">DecisionTreeClassifier 0.788 (0.003)\n",
      "f1 score\n",
      ">DecisionTreeClassifier 0.780 (0.003)\n",
      "auc-roc score\n",
      ">DecisionTreeClassifier 0.684 (0.003)\n",
      "acc score\n",
      ">KNeighborsClassifier 0.793 (0.004)\n",
      "f1 score\n",
      ">KNeighborsClassifier 0.792 (0.004)\n",
      "auc-roc score\n",
      ">KNeighborsClassifier 0.718 (0.003)\n",
      "acc score\n",
      ">SVM 0.815 (0.002)\n",
      "f1 score\n",
      ">SVM 0.809 (0.003)\n",
      "auc-roc score\n",
      ">SVM 0.725 (0.005)\n",
      "acc score\n",
      ">LogisticRegression 0.827 (0.001)\n",
      "f1 score\n",
      ">LogisticRegression 0.821 (0.000)\n",
      "auc-roc score\n",
      ">LogisticRegression 0.738 (0.003)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import mean, std\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "model_names = []\n",
    "\n",
    "scoring_method_f1 = make_scorer(lambda prediction, true_target: f1_score(prediction, true_target, average=\"weighted\"))\n",
    "scoring_method_accuracy = make_scorer(accuracy_score)\n",
    "scoring_method_roc_auc = make_scorer(roc_auc_score)\n",
    "\n",
    "\n",
    "# scoring_method_f1 = 'f1'\n",
    "# # START ANSWER\n",
    "# scoring_method_accuracy = 'accuracy'\n",
    "\n",
    "\n",
    "# evaluate a model\n",
    "def evaluate_model(X, y, model, scorer):\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1, random_state=42)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X, y, scoring=scorer, cv=cv, n_jobs=6)\n",
    "    return scores\n",
    "\n",
    "\n",
    "# evaluate each model\n",
    "for name, model in models.items():\n",
    "    # define steps\n",
    "    steps = list()\n",
    "    steps.append(('c', OneHotEncoder(handle_unknown='ignore'), cat_columns_train))\n",
    "    steps.append(('n', MinMaxScaler(), num_columns_train))\n",
    "    # one hot encode categorical, normalize numerical\n",
    "    ct = ColumnTransformer(steps)\n",
    "    # wrap the model i a pipeline\n",
    "    pipeline = Pipeline(steps=[('t', ct), ('to_dense', DenseTransformer()), ('m', model)])\n",
    "    # evaluate the model and store results\n",
    "    acc_score = evaluate_model(X_train, y_train.values.ravel(), pipeline, scorer=scoring_method_accuracy)\n",
    "    accuracy_scores.append(np.mean(acc_score))\n",
    "    f1 = evaluate_model(X_train, y_train.values.ravel(), pipeline, scorer=scoring_method_f1)\n",
    "    f1_scores.append(np.mean(f1))\n",
    "    auc_sco = evaluate_model(X_train, y_train.values.ravel(), pipeline, scorer=scoring_method_roc_auc)\n",
    "    roc_auc_scores.append(np.mean(auc_sco))\n",
    "    model_names.append(name)\n",
    "    # summarize performance\n",
    "    print(\"acc score\")\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(acc_score), std(acc_score)))\n",
    "    print(\"f1 score\")\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(f1), std(f1)))\n",
    "    print(\"auc-roc score\")\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(auc_sco), std(auc_sco)))\n",
    "# plot the results\n",
    "# plt.boxplot(accuracy_scores, labels=model_names, showmeans=True)\n",
    "# plt.show()\n",
    "\n",
    "# Cross validation plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "bar_width = 0.25\n",
    "X = np.arange(6)\n",
    "\n",
    "p1 = plt.bar(X + 0.00, accuracy_scores, bar_width, color='g',\n",
    "             label='accuracy')\n",
    "\n",
    "# The bar of second plot starts where the first bar ends\n",
    "p2 = plt.bar(X + 0.25, f1_scores, bar_width,\n",
    "             color='b',\n",
    "             label='f1 score')\n",
    "\n",
    "# The bar of second plot starts where the first bar ends\n",
    "p3 = plt.bar(X + 0.50, roc_auc_scores, bar_width,\n",
    "             color='r',\n",
    "             label='roc-auc score')\n",
    "\n",
    "plt.xlabel('Algorithms')\n",
    "plt.ylabel('Performance scores')\n",
    "plt.title('Different classification metrics of algorithms on US Census data')\n",
    "plt.xticks(X + (bar_width + bar_width / 2), (\n",
    "    'GaussianNB', 'Dummy', 'DecisionTree', 'KNN', 'SVM', 'LogisticR'))\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "def autolabel(ps):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in ps:\n",
    "        height = np.round(rect.get_height(), 2)\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(p1)\n",
    "autolabel(p2)\n",
    "autolabel(p3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB\n",
      "- acc_best_score = 0.41521020513867296\n",
      "acc_best parameters:\n",
      "GaussianNB\n",
      "- f1_best_score = 0.3931021210022136\n",
      "f1_best parameters:\n",
      "GaussianNB\n",
      "- roc_best_score = 0.5978607610357284\n",
      "roc_best parameters:\n",
      "DummyClassifier\n",
      "- acc_best_score = 0.7503229731453603\n",
      "acc_best parameters:\n",
      "DummyClassifier\n",
      "- f1_best_score = 0.6432922070446484\n",
      "f1_best parameters:\n",
      "DummyClassifier\n",
      "- roc_best_score = 0.5\n",
      "roc_best parameters:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-f71a5d7208dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m't'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mct\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'to_dense'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDenseTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;31m# evaluate the model and store results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     grid_search_acc = evaluate_model_gridsearch(X_train, y_train.values.ravel(), pipeline,\n\u001b[0m\u001b[0;32m     72\u001b[0m                                                 scorer=scoring_method_accuracy, parameters=parameters)\n\u001b[0;32m     73\u001b[0m     \u001b[0macc_best_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search_acc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-f71a5d7208dd>\u001b[0m in \u001b[0;36mevaluate_model_gridsearch\u001b[1;34m(X, y, model, scorer, parameters)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRepeatedStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# evaluate model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from numpy import mean, std\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "\n",
    "grid_accuracy_scores = []\n",
    "grid_f1_scores = []\n",
    "grid_roc_auc_scores = []\n",
    "\n",
    "model_names = []\n",
    "\n",
    "scoring_method_f1 = make_scorer(lambda prediction, true_target: f1_score(prediction, true_target, average=\"weighted\"))\n",
    "scoring_method_accuracy = make_scorer(accuracy_score)\n",
    "scoring_method_roc_auc = make_scorer(roc_auc_score)\n",
    "\n",
    "\n",
    "# evaluate a model\n",
    "def evaluate_model_gridsearch(X, y, model, scorer, parameters):\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=42)\n",
    "    # evaluate model\n",
    "    grid_search = GridSearchCV(model, parameters, cv=cv, n_jobs=6, verbose=False, scoring=scorer).fit(X, y)\n",
    "    return grid_search\n",
    "\n",
    "\n",
    "model_parameters = {\n",
    "    \"GaussianNB\": {\n",
    "\n",
    "    },\n",
    "    \"DummyClassifier\": {\n",
    "\n",
    "    },\n",
    "    \"DecisionTreeClassifier\": {\n",
    "        'DecisionTreeClassifier__random_state': [random_state],\n",
    "        'DecisionTreeClassifier__max_depth': np.arange(1, 15),\n",
    "        'DecisionTreeClassifier__min_samples_leaf': np.arange(1, 10)\n",
    "\n",
    "    },\n",
    "    # START ANSWER\n",
    "    \"KNeighborsClassifier\": {\n",
    "        'KNeighborsClassifier__n_neighbors': range(1, 10),\n",
    "        'KNeighborsClassifier__weights': ['uniform', 'distance']\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        'SVM__random_state': [random_state],\n",
    "        'SVM__C': np.arange(0.1, 15, 2),\n",
    "        'SVM__kernel': ['linear', 'poly', 'rbf'],\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        'LogisticRegression__random_state': [random_state],\n",
    "        'LogisticRegression__C': np.arange(0.1, 2, 15),\n",
    "        'LogisticRegression__penalty': ['l1', 'l2', 'elasticnet', 'none']\n",
    "    }\n",
    "    # END ANSWER\n",
    "}\n",
    "\n",
    "# evaluate each model\n",
    "for model_name, parameters in model_parameters.items():\n",
    "    model = models[model_name]\n",
    "    # define steps\n",
    "    steps = list()\n",
    "    steps.append(('c', OneHotEncoder(handle_unknown='ignore'), cat_columns_train))\n",
    "    steps.append(('n', MinMaxScaler(), num_columns_train))\n",
    "    # one hot encode categorical, normalize numerical\n",
    "    ct = ColumnTransformer(steps)\n",
    "    # wrap the model i a pipeline\n",
    "    pipeline = Pipeline(steps=[('t', ct), ('to_dense', DenseTransformer()), (model_name, model)])\n",
    "    # evaluate the model and store results\n",
    "    grid_search_acc = evaluate_model_gridsearch(X_train, y_train.values.ravel(), pipeline,\n",
    "                                                scorer=scoring_method_accuracy, parameters=parameters)\n",
    "    acc_best_model = grid_search_acc.best_estimator_\n",
    "    acc_best_score = grid_search_acc.best_score_\n",
    "    acc_best_params = grid_search_acc.best_params_\n",
    "    grid_accuracy_scores.append(acc_best_score)\n",
    "    print(model_name)\n",
    "    print(\"- acc_best_score =\", acc_best_score)\n",
    "    print(\"acc_best parameters:\")\n",
    "    for k, v in acc_best_params.items():\n",
    "        print(\"-\", k, v)\n",
    "\n",
    "    grid_search_f1 = evaluate_model_gridsearch(X_train, y_train.values.ravel(), pipeline, scorer=scoring_method_f1,\n",
    "                                               parameters=parameters)\n",
    "    f1_best_model = grid_search_f1.best_estimator_\n",
    "    f1_best_score = grid_search_f1.best_score_\n",
    "    f1_best_params = grid_search_f1.best_params_\n",
    "    grid_f1_scores.append(f1_best_score)\n",
    "    print(model_name)\n",
    "    print(\"- f1_best_score =\", f1_best_score)\n",
    "    print(\"f1_best parameters:\")\n",
    "    for k, v in f1_best_params.items():\n",
    "        print(\"-\", k, v)\n",
    "\n",
    "    grid_search_roc = evaluate_model_gridsearch(X_train, y_train.values.ravel(), pipeline,\n",
    "                                                scorer=scoring_method_roc_auc, parameters=parameters)\n",
    "    roc_best_model = grid_search_roc.best_estimator_\n",
    "    roc_best_score = grid_search_roc.best_score_\n",
    "    roc_best_params = grid_search_roc.best_params_\n",
    "    grid_roc_auc_scores.append(roc_best_score)\n",
    "    print(model_name)\n",
    "    print(\"- roc_best_score =\", roc_best_score)\n",
    "    print(\"roc_best parameters:\")\n",
    "    for k, v in roc_best_params.items():\n",
    "        print(\"-\", k, v)\n",
    "\n",
    "    # f1 = evaluate_model_gridsearch(X_train, y_train.values.ravel(), pipeline, scorer=scoring_method_f1,\n",
    "    #                                parameters=parameters)\n",
    "    # f1_scores.append(np.mean(f1))\n",
    "    # auc_sco = evaluate_model_gridsearch(X_train, y_train.values.ravel(), pipeline, scorer=scoring_method_roc_auc,\n",
    "    #                                     parameters=parameters)\n",
    "    # roc_auc_scores.append(np.mean(auc_sco))\n",
    "    # model_names.append(model_name)\n",
    "    # # summarize performance\n",
    "    # print(\"acc score\")\n",
    "    # print('>%s %.3f (%.3f)' % (name, mean(acc_score), std(acc_score)))\n",
    "    # print(\"f1 score\")\n",
    "    # print('>%s %.3f (%.3f)' % (name, mean(f1), std(f1)))\n",
    "    # print(\"auc-roc score\")\n",
    "    # print('>%s %.3f (%.3f)' % (name, mean(auc_sco), std(auc_sco)))\n",
    "# plot the results\n",
    "# plt.boxplot(accuracy_scores, labels=model_names, showmeans=True)\n",
    "# plt.show()\n",
    "\n",
    "# Cross validation plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "bar_width = 0.25\n",
    "X = np.arange(6)\n",
    "\n",
    "p1 = plt.bar(X + 0.00, grid_accuracy_scores, bar_width, color='c',\n",
    "             label='accuracy')\n",
    "\n",
    "# The bar of second plot starts where the first bar ends\n",
    "p2 = plt.bar(X + 0.25, grid_f1_scores, bar_width,\n",
    "             color='m',\n",
    "             label='f1 score')\n",
    "\n",
    "# The bar of second plot starts where the first bar ends\n",
    "p3 = plt.bar(X + 0.50, grid_roc_auc_scores, bar_width,\n",
    "             color='y',\n",
    "             label='roc-auc score')\n",
    "\n",
    "plt.xlabel('Algorithms')\n",
    "plt.ylabel('Tuned Performance scores')\n",
    "plt.title('Tuned classification metrics of algorithms on US Census data')\n",
    "plt.xticks(X + (bar_width + bar_width / 2), (\n",
    "    'GaussianNB', 'Dummy', 'DecisionTree', 'KNN', 'SVM', 'LogisticR'))\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "def autolabel(ps):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in ps:\n",
    "        height = np.round(rect.get_height(), 2)\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(p1)\n",
    "autolabel(p2)\n",
    "autolabel(p3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This question is answered in the report.\n"
     ]
    }
   ],
   "source": [
    "print(\"This question is answered in the report.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.preprocessing import DenseTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "\n",
    "steps = list()\n",
    "steps.append(('c', OneHotEncoder(handle_unknown='ignore'), cat_columns_train))\n",
    "steps.append(('n', MinMaxScaler(), num_columns_train))\n",
    "\n",
    "ct = ColumnTransformer(steps)\n",
    "\n",
    "# THIS IS TO DO\n",
    "# WHat model?\n",
    "# WHat parameters?\n",
    "final_clf = LogisticRegression(C=0.1, penalty='none', random_state=42)  # TODO: Include tuned parameters\n",
    "\n",
    "pipeline = Pipeline(steps=[('t', ct), ('to_dense', DenseTransformer()), ('insert-modelname', final_clf)])\n",
    "\n",
    "pipeline.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "final_prediction = pipeline.predict(X_test)\n",
    "\n",
    "prediction = np.array(final_prediction)  # TODO replace this with you own prediction\n",
    "pd.DataFrame(prediction).to_csv(\"GROUP_classes_problem_census.txt\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
